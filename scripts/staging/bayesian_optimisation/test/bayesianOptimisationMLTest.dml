#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------

source("./scripts/staging/bayesian_optimisation/bayesianOptimisation.dml") as bayOpt;

gaussianKernel = function(Matrix[Double] X1, Matrix[Double] X2, Double width = 1)
return (Matrix[Double] result)
{
  square_distance = (X1 - t(X2))^2;
  result = exp((-1)*square_distance/(2 * width^2));
}


l2norm = function(Matrix[Double] X, Matrix[Double] y, Matrix[Double] B) 
return (Matrix[Double] loss) { print("called train function");
  loss = as.matrix(sum((y - X%*%B)^2));
}

upperConfidenceBound = function(Matrix[Double] means, Matrix[Double] variances, Double beta)
return (Double index)
{
  alphas = means + beta * variances;
  index = as.scalar(rowIndexMax(t(alphas)));
}

params = list("icpt", "reg", "tol", "maxi", "verbose");
paramValues = list(as.matrix(0), 10^seq(0,-4), 10^seq(-6,-12), 10^seq(1,3), as.matrix(1));

N = 60;
X = read($1);
y = read($2);

xTrain = X[1:N,];
yTrain = y[1:N,];

Xtest = X[(N+1):nrow(X),];
ytest = y[(N+1):nrow(X),];

opt = bayOpt::m_bayesianOptimisation(
    xTrain = xTrain
  , yTrain = yTrain
  , params = params
  , paramValues = paramValues
  , objective = "lm"
  , predictive = "l2norm"
  , acquisition = "upperConfidenceBound"
  , acquParams = list(2) # beta
  , kernel = "gaussianKernel"
  , kernelParams = list(sqrt(155)) # stddev
  , iterations = 20
  , randomSamples = 5
  , minimize = TRUE
  , verbose = TRUE);

B1 = lm(
  X=Xtest,
  y=ytest,
  icpt = as.scalar(opt[1,1]),
  reg = as.scalar(opt[1,2]),
  tol = as.scalar(opt[1,3]),
  maxi = as.scalar(opt[1,4]),
  verbose = FALSE
);

B2 = lm(X=Xtest, y=ytest, verbose=FALSE);

l1 = l2norm(Xtest, ytest, B1);
l2 = l2norm(Xtest, ytest, B2);

print("\nDefault Params: " + as.scalar(l1) + "\nBayes: " + as.scalar(l2));

R = as.scalar(l1 < l2);
write(R, $3);

