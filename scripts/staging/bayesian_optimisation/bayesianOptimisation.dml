#-------------------------------------------------------------
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
#-------------------------------------------------------------


# INPUT PARAMETERS:
# -----------------------------------------------------------------------------------------------------
# NAME           TYPE           DEFAULT  MEANING
# -----------------------------------------------------------------------------------------------------
# xTrain         Matrix[Double]  ---     Trainings data x used to score the hyperparameter sets.
# y              Matrix[Double]  ---     Trainings targets used to score the hyperparameter sets.
# params         Matrix[String]  ---     Name of the hyper parameters to optimize.
# paramValues    Matrix[Double]  ---     Values of the hyper parameters to optimize.
# objective      String          ---     The objective function to train a model with a set of hyperparameters.
# predictive     String          ---     The predicitve function used to calculate the score.
# acquisition    String          ---     Name of the acquisition function to maximize.
# acquParams     List[Unknown]   ---     List of params to apply to the acquisition function.
# kernel         String          ---     Kernelfunction to use.
# kernelParams   List[Unknown]   ---     List of params to apply to the kernel.
# iterations     Integer         ---     Number of training interations.
# randomSamples  Integer         0       Number of randome samples used to initialize the GaussianP.
# minimize       Boolean         TRUE    Returns HP set with min score if true.
# verbose        Boolean         TRUE    Prints additional information if true.
#

m_bayesianOptimisation = function(Matrix[Double] xTrain, Matrix[Double] yTrain, List[String] params, List[Unknown] paramValues, String objective, String predictive, String acquisition, List[Unknown] acquParams, String kernel, List[Unknown] kernelParams, Integer iterations, Integer randomSamples = 0, Boolean minimize = TRUE, Boolean verbose = TRUE)
return (Frame[Unknown] opt)
{
  numOfParams = length(params);
  HP = getMatrixOfParamCombinations(params, paramValues, verbose);
  numOfHPCombinations = nrow(HP);
  indexes = getNormalizedIndexes(nrow(HP));

  idxScoreMap = getInitScoreAndHyperParamIndexes(
      xTrain
    , yTrain
    , objective
    , predictive
    , HP
    , numOfParams
    , randomSamples
    , verbose
  );

  print("\nhi:\n" + toString(idxScoreMap[,1], rows=nrow(idxScoreMap)) + "\n" + toString(idxScoreMap[,2], rows=nrow(idxScoreMap)));
  [means, variances] = getMeansAndVariances(idxScoreMap, kernel, kernelParams, numOfHPCombinations, verbose);


  for (i in 1:iterations) {

    if(verbose) {
      print("Start iteration " + i);
    }

    idxScoreEntry = matrix(0,1,2);
    # use aquisition function to get index of next hyperparameter set to try.
    aArgs = concatArgsList(list(means, variances), acquParams);
    nextHPSetIdx = as.scalar(eval(acquisition, aArgs)); # Altough double is returned print throw error not being able to print a matrix without toString.
    nextHPSet = HP[nextHPSetIdx];

    # eval expensive objective function with hyperparametsers.
    oArgs = concatArgsMat(list(xTrain, yTrain), nextHPSet);
    oResult = eval(objective, oArgs);

    # score result
    pArgs = list(xTrain, yTrain, oResult);
    pResult = as.scalar(eval(predictive, pArgs));

    idxScoreEntry[i + randomSamples, 1] = nextHPSetIdx;
    idxScoreEntry[i + randomSamples, 2] = pResult;
    idxScoreMap = rbind(idxScoreMap, idxScoreEntry);


    # update model
    [means, variances] = getMeansAndVariances(idxScoreMap, kernel, kernelParams, numOfHPCombinations, verbose);

    if(verbose) {
      print("\nEnd iteration: " + i + "\n sampled HP set: " + toString(nextHPSet) + "\nPredictive: " + toString(pResult));
    }
  }

  [opt, finalIndex, finalScore] = getFinalHPSetAndScore(HP, idxScoreMap, minimize);

  if(verbose) {
    print("Done");
    print("\nFinal sampled HP-index/score:\n" + toString(idxScoreMap, rows=nrow(idxScoreMap)) + "\nOptimal parameters after " + iterations + "iterations:\n" + toString(opt) + "\nIndex:\n" + finalIndex + "\nScore:\n" + finalScore);
  }
}

getMatrixOfParamCombinations = function(List[String] params, list[Unknown] paramValues, Boolean verbose)
return (Matrix[Double] HP)
{
  # Step 0) preparation of parameters, lengths, and values in convenient form
  numParams = length(params);
  paramLens = matrix(0, numParams, 1);
  for( j in 1:numParams ) {
    vect = as.matrix(paramValues[j,1]);
    paramLens[j,1] = nrow(vect);
  }
  paramVals = matrix(0, numParams, max(paramLens));
  for(j in 1:numParams) {
    vect = as.matrix(paramValues[j,1]);
    paramVals[j,1:nrow(vect)] = t(vect);
  }
  cumLens = rev(cumprod(rev(paramLens))/rev(paramLens));
  numConfigs = prod(paramLens);

  # Step 1) materialize hyper-parameter combinations
  # (simplify debugging and compared to compute negligible)
  HP = matrix(0, numConfigs, numParams);

  parfor( i in 1:nrow(HP) ) {
    for( j in 1:numParams )
      HP[i,j] = paramVals[j,as.scalar(((i-1)/cumLens[j,1])%%paramLens[j,1]+1)];
  }

  if( verbose ) {
    print("BayesianOptimization: Hyper-parameter combinations(" + numConfigs + "):\n"+toString(HP, rows=nrow(HP)));
  }
}

getInitScoreAndHyperParamIndexes = function(Matrix[Double] xTrain, Matrix[Double] yTrain, String objective, String predictive, Matrix[Double] HP, Integer numOfParams, Integer numOfRandomeSamples, Boolean verbose = TRUE)
return(Matrix[Double] idxScoreMap) {
  maxIndex = nrow(HP);
  samples = sample(maxIndex, numOfRandomeSamples);
  usedHPs = matrix(0, numOfRandomeSamples, numOfParams);
  idxScoreMap = matrix(0, numOfRandomeSamples, 2);

  for (sampleIdx in 1:numOfRandomeSamples) {
    rndNum = as.scalar(samples[sampleIdx,1]); 
    idxScoreMap[sampleIdx,1] = rndNum;
    HPSet = HP[rndNum,];

    # calc objective
    oArgs = concatArgsMat(list(xTrain, yTrain), HPSet);
    usedHPs[sampleIdx,] = HPSet[1,];
    objResult = eval(objective, oArgs);

    # calc predictive / score
    pArgs = list(xTrain, yTrain, objResult);
    predResult = as.scalar(eval(predictive, pArgs);)
    idxScoreMap[sampleIdx,2] = predResult;
  }

  if (verbose) {
    print("\nInit model with randome samples:");
    print("\nNormalized Indexes/Scores:\n" + toString(idxScoreMap[,2], rows=nrow(idxScoreMap)) +
          "\nhyperparameters:\n" + toString(usedHPs, rows=nrow(usedHPs)));
  }
}

getNormalizedIndexes = function(Integer numOfSamples)
return (Matrix[Double] indexes)
{

  indexes = matrix(0, numOfSamples, 1);
  for (i in 1:numOfSamples) {
    indexes[i,1] = i/numOfSamples;
  }
}

getMeansAndVariances = function(Matrix[Double] idxScoreMap, String kernel, List[Unknown] kernelParams, Double numOfHPCombinations, Boolean verbose)
return (Matrix[Double] means, Matrix[Double] variances)
{

  sampledIndexes = idxScoreMap[,1];
  scores = idxScoreMap[,2];

  KArgs = concatArgsList(list(sampledIndexes, sampledIndexes), kernelParams);
  K = eval(kernel, KArgs);
  print("\nK:\n" + toString(K));
  K_inv = inv(K);

  means = matrix(0, numOfHPCombinations, 1);
  variances = matrix(0, numOfHPCombinations, 1);

  parfor (i in 1:numOfHPCombinations) {

    xNew = as.matrix(i);
    print("xNew: " + toString(xNew));
    KsArgs = concatArgsList(list(sampledIndexes, xNew), kernelParams);
    Ks = eval(kernel, KsArgs);

    KssArgs = concatArgsList(list(xNew, xNew), kernelParams);
    Kss = eval(kernel, KssArgs);

    #print("mean/variance: " + i);
    #print("Ks: " + toString(Ks) + "\nK_inv: " + toString(K_inv) + "\nKss: " + toString(Kss) + "\nscores: " + toString(idxScoreMap[,2]));
    #print("t(Ks) %*% K_inv %*% Ks: " + toString(t(Ks) %*% K_inv %*% Ks));
    #print("Kss: " + toString(Kss));
    #print("(t(Ks)%*%K_inv): " + toString(t(Ks)%*%K_inv));

    means[i,1] = as.scalar(t(Ks)%*%K_inv%*%scores);
    variances[i,1] = as.scalar(Kss - t(Ks) %*% K_inv %*% Ks);
  }

  if (verbose) {
    print("\nMeans:\n" + toString(means, rows=nrow(means)) + "\nVariances:\n" + toString(variances, rows=nrow(variances)));
  }

}

concatArgsList = function(List[Unknown] a, List[Unknown] b)
return (List[Unknown] result)
{
  result = a;
  if ( length(b) != 0 ) {
    for(i in 1:length(b)) {
      result = append(result, b[i]);
    }
  }
}

concatArgsMat = function(List[Unknown] a, Matrix[Double] b)
return (List[Unknown] result)
{
  result = a;
  for(i in 1:ncol(b)) {
    result = append(result, as.scalar(b[1,i]));
  }
}

getFinalHPSetAndScore = function(Matrix[Double] HP, Matrix[Double] HPIdxScoreMap, Boolean minimize)
return (Frame[Unknown] opt, Double index, Double score)
{
  if (minimize) {
    mapIdx = as.scalar(rowIndexMin(t(HPIdxScoreMap[,2])));
  } else {
    mapIdx = as.scalar(rowIndexMax(t(HPIdxScoreMap[,2])));
  }

  index = as.scalar(HPIdxScoreMap[mapIdx,1]);
  opt = as.frame(HP[index]);
  score = as.scalar(HPIdxScoreMap[mapIdx,2]);
}
